%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the 
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,obeyspaces]{acmart}
\settopmatter{printacmref=false}
\setcopyright{none}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%%\BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
   \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\begin{comment}
These commands are for a PROCEEDINGS abstract or paper.
%%\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
 %% Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
%%\acmPrice{15.00}
%%\acmISBN{978-1-4503-XXXX-X/18/06}
\end{comment}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[backend=biber]{biblatex}
\usepackage{listings}
\usepackage[font={small,it}]{caption}
\usepackage{enumitem}
\addbibresource{NLGRef.bib}



%%
%% end of the preamble, start of the body of the document source.

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Representations and Appropriate Simplifications of Data Accesses With Natural Language Generation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Leon Brooks}
\affiliation{%
  \institution{Seminar Inverse Transparency (WS 20/21)\\Advisor: Valentin Zieglmeier}
}
\email{leon.brooks@tum.de}
%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Data protection and privacy concerns are as relevant as ever and a topic that may significantly shape the future of our society. Companies and consumers alike have realized the value of data, although many people demand more insight on how their own data is used. Inverse Transparency offers a solution to relieve these tensions by informing owners when and how their data was accessed. This paper focuses on implementing Inverse Transparency through natural language generation systems to increase the accessibility and understanding for ordinary users. A simple example is conceptualized and implemented using the Jira REST API to modulate data accesses. Finally approaches to evaluating readability aspects are discussed. 
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Inverse Transparency, natural language generation, data privacy, readability, Jira}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In recent times the importance of data as valuable good has increased and most people are aware of this development~\cite[10\psq]{symantec_State_of_Privacy}. At the same time around 50--60\% feel their data is not safe online~\cite[6\psq]{symantec_State_of_Privacy}~\cite[22\psq]{Bitkom_Datenschutz}. People do care however what happens with their data~\cite[24\psq]{Bitkom_Datenschutz} and over 80\% expect companies to inform them how their data is used. Some would even shy away from using a product where they do not understand how data is used~\cite{BVDW_Datenschutz}. This has given rise to the concept of Inverse Transparency which demands transparency to owners over when and how their data is used for each individual data access~\cite{gierlich_jonas}. It is based on the non-fiction book "The Transparent Society" by the science fiction author David Brin~\cite{Brin_1998}, an extract of which first appeared in the magazine Wired in 1996~\cite{Brin_1996}. In it, Brin describes a future of "open access" in which cameras monitor every public space and citizens, government and companies alike can freely monitor ones every move. As one solution for problems that may arise from this he suggests the "mutual-transparency solution" in which the system tells every monitored person who is watching them.

A problem that arises when implementing the more modern concept of Inverse Transparency is that the plain meta data, represented through access logs, may not be the optimal way to display data accesses to data owners. Therefore it is essential that the meta data is presented in a way that is easily readable and can be understood by ordinary people for Inverse Transparency to function as intended.

This paper will focus on ways to implement Inverse Transparency by displaying meta data as humanly readable sentences through natural language generation (NLG) systems. The applicability of readability metrics as well as the process of building a natural language generation system will be covered and implementation examples will be shown.

\section{Motivation}
As touched on above, the primary intent of this paper stems from the question how to properly implement Inverse Transparency through an automated system in a form that is able to be understood by ordinary data owners. This should suggest a solution to the problem that true transparency can only be realized if every data owner can actually understand what is happening and in which way their data is used on a conceptual level instead of only being presented unrefined meta data.

In this paper the focus shall lie on giving an exemplary implementation of such a system and exploring questions that arise along the way of that process. This should build a foundation for improving and expanding Inverse Transparency systems and possibly encourage further research on the topic.


\section{Conceptualization} \label{concept}
This section shall focus on the requirements and specifications the exemplary implementation for this paper is supposed to fulfill. The relevance and basic functionality of the Jira REST API is shown and the usage in this system explained. Furthermore it is discussed which types of data accesses can and can not be detected given the specification and how these tie in with Jira.

\subsection{Introduction and Usage of the Jira Rest API} \label{jira}
Before one can build a NLG-system for an Inverse Transparency solution an input data set which describes the actual instances of user data being accessed is required. For this project the Jira REST API is used to implicitly define such a data set.

Jira is is a software system developed by the Australian company Atlassian which is used to manage agile software development life cycles such as Scrum.\footnote{\texttt{\url{https://www.atlassian.com/software/jira}}} Internally the software represents development tasks and goals with so called "Issues". They hold relevant meta data such as due date, assignee, time spent, etc. as well as user created remarks and comments.\footnote{\texttt{\url{https://developer.atlassian.com/server/jira/platform/attachments/jira-7-9-2-database-schema.pdf}}} Jira fits well as an implementation example as it is a platform which while performing it's primary purpose, providing an organization structure for agile software development, also provides the data for managers to monitor their subordinates work and performance. This is a practical scenario in which Inverse Transparency may help reduce tensions that arise from the increase in availability of performance related data in the workplace~\cite[10\psqq]{gierlich_jonas}.

The Jira representational state transfer (REST) API can be used to interact with a Jira database via the HTTP protocol to allow third party developers to integrate a Jira database into their own software system. To access data one must generate a HTTP request which contains a search query for a specific or a group of issues\footnote{\texttt{\url{https://developer.atlassian.com/server/jira/platform/rest-apis/}}}. One then receives a HTTP response containing a JSON representation of the requested issues. A request like this; 
\begin{center}
    \url{https://jira.atlassian.com/rest/api/latest/issue/JRA-9}
\end{center}
could be used to retrieve the issue "JRA-9" from Atlassian's public issue tracker.

This project will use Jira REST API requests to represent instances of data access. Consequently the assignee, reporter and creator of a Jira issue are representing the data owners in the Inverse Transparency context. On a more concrete level the NLG-system will receive tuples of a HTTP request link and an accessing person as input. Then the requests will be analyzed and one or multiple sentences will be formed to express which data was accessed and what noteworthy patterns were detected therein.

It must be stressed that the system will neither implement the execution of the API requests nor generate the output from the hypothetical received data, but rather analyze the structure of the API request to form the resulting sentences.

Besides simply requesting a specific issue a request can instead contain a search query made of a Jira Query Language\footnote{\texttt{\url{https://www.atlassian.com/software/jira/guides/expand-jira/jql}}}\footnote{\texttt{\url{https://3kllhk1ibq34qk6sp3bhtox1-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/atlassian-jql-cheat-sheet-2.pdf}}} (JQL) term. This would then return a collection of issues fulfilling the search query instead. A JQL term is built by combining search reference fields\footnote{\texttt{\url{https://support.atlassian.com/jira-software-cloud/docs/advanced-search-reference-jql-fields/}}} of a Jira issue with specific operators\footnote{\texttt{\url{https://support.atlassian.com/jira-software-cloud/docs/advanced-search-reference-jql-operators/}}} and search values. Since the scope of JQL terms far exceeds those relevant to realizing the Inverse Transparency concept the allowed input will be limited to the following ones:
\begin{itemize}\obeyspaces
    \item field = user
    \item field != user
    \item field IN (user,user,user,...)
    \item field NOT IN (user,user,user,...)
    \item field WAS user                                        [options]
    \item field WAS NOT user                               [options]
    \item status WAS "Resolved" BY user              [options]
    \item status WAS NOT "Resolved" BY user     [options]
\end{itemize}
with field being either assignee, reporter or creator and user being a username, ID or e-mail address. [options] indicates optional date related clauses of the WAS operator (AFTER, BEFORE, ON, DURING). A request like this for example;
\begin{center}
    \url{https://jira.atlassian.com/rest/api/latest/search?jql= status WAS Resolved BY "mike@atlassian.com"}
\end{center}
would return all issues that were resolved by the user with the e-mail address "mike@atlassian.com".

For these types of requests it arguably appears to be more fitting to only notify the user(s) targeted within the search queries as only they are part of the intent of the data access. For example if a superior searches for all issues resolved by a certain user it does not make sense to notify the creator and reporter of every issue as well.
 
\subsection{Detecting Relevant Patterns Within Instances of Data Access} \label{patterns}
Simply notifying the user when and which of his data has been accessed may be an important task of a software system implementing Inverse Transparency, but on its own arguably does not add significantly more value than simply displaying logs. Therefore, one must ask themselves which types of access behaviours may be of special interest to data owners, how they can be determined from the access data and in which way the NLG-system should emphasize them.

Since no literature or surveys on this specific question could be found some plausible examples were chosen. These include a single person accessing a large amount of data from a specific owner, a person accessing certain data on a regular basis/in fixed intervals or a specific set of data being accessed by many users. 

Before applying these patterns to the system however, one must address the notion of time first. As mentioned in \ref{jira} the system shall receive tuples of the accessing person and the Jira API request as input. This poses a problem since it would not be sufficient to realize a time frame based analysis. On the other hand implementing timestamp parsing and a calendar based tracking or real time notification system is beyond the scope of this simple system, as the main focus of this project lies on the NLG component.

To solve this discrepancy it shall be defined that the input contains all access data of a certain fixed time frame. This could be a week, a month or an arbitrary number of days. Since the concrete time frame matters for the NLG, it will be given as a startup parameter. Intuitively this should imply that the data accesses (i.e. the Jira API requests) are tracked externally and the system is then run every week/month/etc with the access data as Input.

At this point it makes sense to specify the output format as well. Similarly to the input the output will consist of tuples of a natural language message and the intended recipient.

With these specifications complete, the question remains which of the patterns mentioned above can be detected within this system and how they can be derived from the input data.

A person accessing large amounts of data from a specific owner can be detected very easily by simply counting the =, IN and WAS operator calls. If they pass a certain predetermined threshold they are considered noteworthy.

Detecting a person accessing data on a regular basis is not possible however, given the specification set above. Without concrete timestamps or a database storing of results over multiple runs of the application this is not feasible.

As with the previous pattern, a specific data set being accessed by many users is not detectable since only the queries, not the actual issues returned by them, are known. A similar goal however can be achieved by tracking how many users searched for a specific owner using the =, IN and WAS operators.

Besides the pattern based approach it might be of interest to an owner if a rare request occured or a request which may imply a certain intent was issued. All negated operators (!=,NOT IN, WAS NOT) should represent the first category as it is arguably less common to search which issues a person was not involved in or did not resolve. The second category can be represented by queries including the "Resolved" BY clause or request with date specific options. These request are, amongst other purposes, also used when monitoring responsibility, accountability and productivity. Therefore they will justify a separate notification in this system.

\section{Implementation} \label{impl}
This section will show, step by step, the concrete realization of the requirements and functionalities specified in~\ref{concept}. At the same time it will be shown how this implementation relates to common NLG design concepts.

The programming language chosen for this project is Java. This is due to the rich functionality of the Java String class and the simple concatenation through the + operator.
The complete implementation is available on GitHub.\footnote{\texttt{\url{https://github.com/LeonBrooks/Inverse-Transparency-NLG}}}

\subsection{Input and Output Format}
A common practice for specifying requirements of a NLG-system is the corpus based approach~\cite[5]{reiter_dale}, where concrete input and output examples are used to define the functionality a NLG-system should have. In section~\ref{concept} a similar thing was done on a more abstract level by defining the input and output tuples\footnote{in: (requester, HTTP Jira REST API request), out: (recipient, data acess description message)}. Here we want to further elaborate on the concrete form this will take in the implementation.

The program will take the input as a txt file, the path to which is given by a startup parameter, that holds the tuples. As a separator character between requester and request "\{" will be used since it is neither part of the URI\footnote{as defined in RFC 3986: \texttt{\url{https://tools.ietf.org/html/rfc3986}}} nor the JQL alphabet. Tuples themselves will be separated through new lines. A valid line of the input file could look like this:
\begin{center}
    James\{https://jira.atlassian.com/rest/api/latest/search?jql=creator = Peter
\end{center}

The output will be written to a txt file as well. For each user appearing in one or multiple search request one message will be generated. The message is a summary of all notable accesses detected within the input and may consist of multiple sentences. The exact format will not be further specified.

\subsection{System Components and Class Structure}
In their Book "Building Natural Language Generation Systems"~\cite{reiter_dale_2000} Ehud Reiter and Robert Dale describe a popular model for building NLG-systems. Although not without criticism~\cite[3\psqq]{mellish_scott_cahill_paiva_evans_reape_2006}, it "Arguably [...] is still the most complete available survey of NLG"~\cite[5]{gatt_Krahmer}. It describes six basic tasks a NLG-system fulfills to get from input data to a finished text:
\begin{enumerate}[label=\arabic*.]
    \item \emph{Content Determination:} choosing which parts of the input data will appear in text later
    \item \emph{Discourse Planning:} ordering/giving a structure to the items created in the previous task
    \item \emph{Sentence Aggregation:} deciding which items will be part of the same sentence
    \item \emph{Lexicalization:} deciding which words to choose to express the information the items represent
    \item \emph{Referring Expression Generation:} choosing pronouns or phrases which can be used to refer to items to increase fluidity of the final text (e.g.: it, her, himself, etc.) 
    \item \emph{Linguistic Realisation:} the final step of forming correct sentences from the chosen words
\end{enumerate}
These tasks are then distributed over three different modules (see Figure \ref{modules_fig}) used to implement NLG-systems. The Text Planner is responsible for tasks 1 and 2, the Sentence Planner fulfills 3,4 and 5 while the Linguistic Realiser implements task 6.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.3]{"NLG Reiter Dale Fig".png}
    \caption{Figure by Reiter and Dale~\cite{reiter_dale} explaining their NLG-system architecture model. Boxes stand for modules while text stands for the output of each module}
    \label{modules_fig}
\end{figure}
Since this application is rather simple and fairly static in its outputs, a sophisticated structure like this is not required and would only over complicate the implementation with little benefit. It is a very useful guideline however to help formulating ones own approach to building a NLG-system.

When for example asking the question: "How and where would Content Determination appear in this system", one realizes that this would most likely fit the counting and dissection of the search request for each user. More specifically this would mean iterating over all search requests and keeping track of how often each user was targeted in each different type of request.

Once this data is complete one could continue with the other tasks. For our system however it is clear that in the end a few similar sentences combined with variables can be used to derive all possible output messages. This is a case where a template based approach appears to be a well suited option~\cite[16]{gatt_Krahmer}. Templates can be summarized to be predefined sentences including placeholder variables. They can usually look somewhat like this:
\begin{enumerate}
    \item Your colleague \emph{\$requester} searched for you \emph{\$count} times.
\end{enumerate}
The main task of the system is then to choose the sentences and set the variables according to the precomputed data.

This then suggests a two module architecture for this system. An \texttt{InputAnalyzer} which reads the input and creates a data set for further processing and a \texttt{TextGenerator} that takes this data and compiles the output. Therefore the Content Determination task is fulfilled by the \texttt{InputAnalyzer} while the remaining tasks are handled by the \texttt{TextGenerator}. The Discourse Planning, Sentence Aggregation and Lexicalization task although are strictly speaking not actively performed but rather implicitly given by the template setup.

\subsection{Concrete Implementation Details}
Besides the \texttt{InputAnalyzer} and \texttt{TextGenerator} modules the complete program will also include two more classes. A Main class which contains the main method that reads from the input file and writes to the output file. As arguments the main method takes:
\begin{itemize}
    \item The path to the input file
    \item The path to the output file
    \item A string that describes the time frame (e.g. "week", "month", "15 days")
    \item An integer \texttt{threshold} that is the maximum number of requests issued by the same user, which are considered not noteworthy
    \item An integer \texttt{multiuserThreshold} that is the maximum number of requesters querying for the same users, which are considered not noteworthy
    \item an optional string "detailed", which will cause the program to print exact numbers and listings
\end{itemize}
The \texttt{RequestExtract} class functions as a data object that contains all the relevant metrics needed to properly navigate the templates within the \texttt{TextGenerator} class.
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{"RequestExtract UML".png}
    \caption{Class diagram of \texttt{RequestExtract}}
    \label{RequestExtract UML}
\end{figure}
One \texttt{RequestExtract} object represents all the data needed to generate a message for an individual data owner. It has five attributes of which the first two contain the total amount of request made targeting a user and the number of unique requesters, while the remaining three contain the data needed to realize the pattern detection specified in \ref{patterns}.

The \texttt{highRequesters} attribute maps requesters whose request count exceeded the \texttt{threshold}, to an object of the inner class counter that tracks the queried field of all requests. Negatives maps requesters who made negative requests (!=, NOT IN, WAS NOT) to a list of integers from which the request type can be determined. And the performance attribute maps requesters that made request that could be related to tracking the performance of a user, to an object of the inner class Details that contains a complete breakdown of those request.
\begin{figure*}
    \hspace*{-1.8cm}
    \includegraphics[scale=0.58]{"NLG UML".png}
    \caption{Class diagram of the complete system}
    \label{Full UML}
\end{figure*}

\subsubsection{Input Analyzer}\label{input}
The \texttt{InputAnalyzer} class is responsible for converting the Jira REST API request strings into data objects the \texttt{TextGenerator} can easily interpret and use to generate the final messages. Therefore, it creates a \texttt{RequestExtract} object for every user who appeared in any request, which summarizes all requests that user was targeted by.

This is handled by the static method \texttt{analyzeInput()} which receives a list String[] and the \texttt{threshold} argument as input (see Figure \ref{Full UML}). Each array has the size 2 and contains the requesting user and the request. It returns a Map associating each targeted user to their individual Request extract.

To accomplish this the method iterates over all requests and fills the output map accordingly. As a first step the request string is cut down to only the JQL portion (e.g. creator !=  Paul) and the request type is determined (one of the eight types defined in \ref{jira}). Then the targeted users are identified and for each of them the corresponding \texttt{RequestExtract} is retrieved from the result map. If the user appeared for the first time a new \texttt{RequestExtract} is created.

The request is then categorized as performance related, negative or standard. The related checks are performed in that order. Performance related requests are those which query for WAS (NOT) "Resolved" BY or those which contain a date specific option. Negative request, as the name implies, contain a negated operator and all other request are classified as standard.

For performance related and negative requests, new items are inserted into the lists associated to the user who issued the request. For negative request this is only a single Integer which represents the negative request type. 

This is not the standard request type ranging from 0--8 however. Since all negative requests query for a field (assignee, creator, reporter), otherwise they would be categorized as performance related, the only other difference is if they queried for a single (!=,WAS NOT) or for multiple users (NOT IN). Therefore, the negative request type is mapped to 0--5 as follows:
\begin{itemize}
    \item type = 0: single user querying for assignee field
    \item type = 1: single user querying for reporter field
    \item type = 2: single user querying for creator field
    \item type = 3--5: multi user querying for assignee, report, creator
\end{itemize}
For all request the Counter object associated with the requesting user within the \texttt{highRequesters} attribute is updated accordingly (request querying for "Resolved" BY count towards the assignee field) and the total attribute is incremented.

Lastly after all requests have been processed the \texttt{uniqueUsers} attribute is set for every \texttt{RequestExtract} object. It can simply be set to the size of the \texttt{highRequesters} map as, at this point, every requester has an entry within it. Finally all requesters whose combined request counts (Counter.sum()) are below the \texttt{threshold} parameter are removed from the \texttt{highRequesters} map.

\subsubsection{Text Generator}
The \texttt{TextGenerator} class consist of the static method \texttt{generateTextFromExtracts()} which takes the map created by the \texttt{InputAnalyzer}, the \texttt{timeframe}, the \texttt{detailed} boolean, the \texttt{threshold} and the \texttt{multiuserThreshold} as parameters and returns a map associating each requested user with the message they are supposed to receive. The creation of each individual message is outsourced into the private \texttt{generateMessage()} method which takes a \texttt{RequestExtract} instead of the map and the same remaining parameters as the \texttt{generateTextFromExtracts()} method.

At first glance it may seem simple to build a template based NLG-system but in practice there are quite a few details to pay attention to. In this case the message generation is split into four major parts according to the patterns defined in \ref{patterns} and represented by the \texttt{RequestExtract} attributes. Besides the overall decision making process of which patterns to include, for each part some grammar and logic related actions must be performed as part of the Linguistic Realisation task.
\begin{itemize}
    \item \emph{Agreement}: Some words need to be adjusted depending on other words they relate to. For example the words \emph{colleague} and \emph{is} must agree in number in the phrase: "[...] your colleagues were interested in [...]" (3-rd person plural). It can not be "[...] your colleagues was interested in [...]" (\emph{colleague}: 3-rd person plural, \emph{is}: 3-rd person singular).
    %%\item Morphology
    \item \emph{Punctuation rules}: When enumerating for example, two people must be separated with an and, but for more people, the first x people must be separated by a comma while the last two should still be separated by an and.
    \item \emph{different formulation according to predecessors}: To enhance the fluidity and readability of the result, each text block connected to a pattern will differ depending if previous patterns were detected or not. 
    
    For example the second of the two blocks "Many people accessed your data this week. Specifically your colleague John was interested in [...]" will change to "Your colleague John was interested in [...] over the last week" if the pattern connected to the first was not detected.
\end{itemize}
Adjustments for all these factors are made in every block described in the following and, although arguably the most effort in the actual implementation,  are not detailed further as this would most likely only be a list of questions similar to: "Does x word need a plural s appended in this, this and that case ?". For interested readers I refer to the complete implementation.\footnote{\texttt{\url{https://github.com/LeonBrooks/Inverse-Transparency-NLG}}}

As mentioned above the text is generated in four major blocks each connected to a pattern. The first is the relatively simple question, if many individual people made requests querying for the user in question. If this is the case the first sentence will be: "Many people accessed your data this week."

The next block is connected to the pattern if a singular user has a high request count. As mentioned in \ref{input} every requester that fulfills this criteria has an entry in the \texttt{highRequesters} attribute of the \texttt{RequestExtract}. If applicable respect is paid to which field(s) they requested the most. This then generates sentences like: "Specifically your colleague John seemed very interested in which issues you created and were working on." or "Your colleagues Jill, Joe and Mike seemed very interested in your activity over the last week."

The third block is related to whether people made negated requests. It functions similarly to the previous one and produces output like: "Additionally your colleague Tara made requests a request from which they can deduce on which issues you were not the assignee." or "Your colleagues made requests from which they can deduce on which issues you were not the assignee, creator or reporter over the last week."

The last block is dedicated to possibly performance related requests. Here requesters are grouped into categories depending on what types of requests they made. These categories include requests that were querying for which issues an assignee did and did not resolve and requests that had a date options attached to them. This can produce sentences like: "Some of your colleagues also made requests which could be related to tracking your performance or responsibilities:
Patrick and John were interested in which issues you resolved, Tina was interested in which issued you did not resolve and Tom, Bill and Jane checked if you were involved in an issue within a certain time frame."

Finally as touched on above the detailed options will cause additional information to be printed for each block. For the first that is the total number of requests. For the second this is a print out of the counter object for each "high requester". Similarly, for the negated requests the number of request of each requester are printed out by type. Lastly for the performance related request a breakdown of every individual request is given. Just like the remaining message, all of these are formulated in natural language as well.

\section{Evaluating the Readability of Generated Language}
One of the stated goals of this paper is to give an exemplary implementation of a NLG-System which may help ordinary users understand access mad to their data. For this to be achieved it must be assured that users actually understand the output of the system. Therefore one must find appropriate metrics to evaluate the generated messages.

\subsection{Applicability of Classic Readability Metrics}
At first it may seem appropriate to use methodologies from the field of readability studies. There are different definitions of readability but the work in this field may be summarized by the concern of ensuring a text affects the reader in the way the author intends~\cite[1]{Zamanian_Heydari}. Many different metrics have been developed to evaluate the readability of a text and most use average sentence length and a form of word length (e.g syllables per word) as primary variables to determine the difficulty of a text~\cite[2\psqq]{Zamanian_Heydari}.

In the context of NLG-systems and this particular case they may seem unfit for three main reasons. First and foremost readability metrics were developed with the goal of evaluating longer texts like (text)books or newspaper articles~\cite{Zamanian_Heydari}. For two popular formulas, the Flesch Reading Ease and Flesch-Kincaid Grade Level, Graesser et al. stated they could only be successfully applied for texts with more than 200 words~\cite[7]{Graesser}. Another popular metric created by Edward Fry~\cite{Fry} uses three 100 word samples to determine an appropriate age of the reader. The output of this NLG-system only produces messages of about 100 words in total and although not explicitly stated for every readability formula, this seems not to be the intended type of text.

Secondly, the fact that readability metrics cannot make proper judgements on how well a text will be understood by the reader~\cite[9]{Zamanian_Heydari} cannot be ignored. Although very similar intuitively, readability and understanding a text do not have exactly the same meaning in this context. The nuanced difference here is in the overall fluidity and understanding what the words of a text say versus understanding the meaning behind the text. As the latter is specifically what this system tries to achieve this makes them of little use in this case.

And finally it must be considered that as mentioned above classic readability metrics were developed to evaluate human authored text. Even if one would only want to evaluate the fluidity of generated text, metrics based on average sentence length, average word length and possibly even different list of easy or difficult words seem sub optimal. If, for example, the referring expression generation of a NLG-system were missing the text generated could look like this:
\begin{center}
    \emph{Tom went to the store to go shopping. There Tom bought apples, pears and some vegetables. Tom needed the fruit for Tom while the vegetables were for Tom's mother.}
\end{center}
This is arguably less readable and fluid than:
\begin{center}
    \emph{Tom went to the store to go shopping. There he bought apples, pears and some vegetables. He needed the fruit for himself while the vegetables were for his mother.}
\end{center}
Human authors would most likely never produce the first text. Therefore classic readability formulas based on the metrics mentioned above were not developed to detect such problems and would score both texts quite similarly.

For these reasons it seems inappropriate to use classic readability metrics to asses NLG-systems and especially in this case further research may be required to properly evaluate how well the generated messages convey and summarize the different data accesses.

\subsection{Readability Survey}
Although classic readability metrics are not applicable this paper does however aim to provide some form of readability evaluation. Therefor a public survey was performed. It must be stressed that the goal was not to produce a scientifically or statistically representative evaluation but rather to gather first insight into the quality of the generated output.

The survey was taken by 23 participants and had no restrictions concerning any types of prerequisites. The complete form including all questions and answers with diagrams can be found in the appendix (section \ref{appendix}) as well as online (only answers).\footnote{\texttt{\url{https://docs.google.com/forms/d/e/1FAIpQLSfiAKzNv1pOcEVXhZK7Ic3JtFh-hkzi776_gctJfN1f320W-w/viewanalytics?usp=form_confirm}}}

In total six questions were asked in reference to a single output message:
\begin{enumerate}
    \item Did participants have any previous experience with Jira
    \item How fluent and natural did the output sound
    \item How well did the participants think they understood the output
    \item How easy did they think the output was to understand in general
    \item How well did the message represent the queries it was generated from
    \item In what ways could the output be improved
\end{enumerate}
The message was the output form accesses containing all four patterns described in sections \ref{concept} and \ref{impl}. Before the questions were asked brief explanations of the concepts of Inverse Transparency, NLG and Jira were given. Evaluation questions were based on a scale of 1 to 4.

In total only 13\% (3) of participants were familiar with Jira. The fluidity of the message appeared to be satisfactory with lowest score being 2 which was only given by 17\% (4). A large majority of 65\%(15) thought they understood the message completely and only one person, who gave a score of 2, had problems comprehending the output. Curiously the simplicity of the message in general was rated slightly worse. Only 39\% (9) participants thought everyone could understand the message and a score of 2 was given by 26\% (6) people here instead. This may indicate that most participants considered themselves to be better qualified to understand the message than the general public.

For the last evaluation question the participants were presented with all the queries which were used to generate the message they had been previously judging. In addition to grading how well the output summarized the request queries they had the option to not give an answer because they did not understand the request format. About half gave a score of 3, a quarter a score of 4 and the remaining quarter consisted of three people who did not understand the format and three people who gave a score of 2. The last question could be answered freely in text and participants made a wide variety of suggestions to improve the system. The full list of these can be found in the appendix as well.

Overall the system appears to fulfil its purpose of generating messages which can convey data accesses to a general public. Although there is definitively room for improvement, no participant gave a sore of 1 on any question and on every question at least 74\% (17) gave a score of 3 or 4. Especially since all but three participants had no previous experience with Jira this can be seen as a satisfying result considering the stated purpose. Specifically even all three participants that did not understand the request format scored their own comprehension of the message at least a 3. This indicates the system might even be able to allow people who would not understand plain access logs to get an insight on how their data was used.

\section{Conclusion}
In this paper the basic concept of Inverse Transparency and how NLG-systems may help implement it was explained. A simple system based on analyzing accesses made through the Jira REST API was implemented. It was shown how and to which degree NLG design concepts are helpful when conceptualizing a basic system and how they translate to concrete implementation solutions. Lastly a short look was taken at why classic readability metrics may not be suited to evaluate NLG-system in general and what problems arise in this specific case. Instead a simple survey was conducted to gather a surface level understanding of the quality of the output. Its results indicate the system likely achieves its goal of giving ordinary people an insight into how their data is used. 

This should help to set a stepping stone for further research on practical solutions in the field of Inverse Transparency. Especially the evaluation of implementations of this concept may require new solutions and research in this area should be strongly encouraged.


\section{Contribution}
The paper aims to contribute to the topics of Inverse Transparency and natural language generation systems by giving an exemplary implementation and elaborating on common features, function and requirements of such systems. This practical approach to Inverse Transparency may help people unfamiliar with the topic to understand it's purpose and potentially serve as a foundation to build more complex and sophisticated systems.

\nocite{*}
\sloppy
\printbibliography
\fussy

\newpage
\onecolumn
\appendix 
\section{Survey Questions} \label{appendix}
\begin{center}
    \hspace*{-0.48cm}
    \includegraphics[scale=0.45]{"Questions-1".png}
\end{center}
\begin{center}
    \vspace*{-1.5cm}
    \hspace*{-0.6cm}
    \includegraphics[scale=0.5]{"Questions-2".png}
\end{center}
\begin{center}
    \vspace*{-1.8cm}
    \hspace*{-0.5cm}
    \includegraphics[scale=0.42]{"Questions-3".png}
\end{center}
\begin{center}
    \vspace*{-1.5cm}
    \hspace*{0.5cm}
    \includegraphics[scale=0.45]{"Questions-4".png}
\end{center}

\newpage
\section{Survey Answers}
\begin{center}
    \vspace*{1.2cm}
    \hspace*{-0.2cm}
    \includegraphics[scale=0.37]{"Answers-1".png}
\end{center}
\begin{center}
    \vspace*{-1.5cm}
    \hspace*{-0.2cm}
    \includegraphics[scale=0.45]{"Answers-2".png}
\end{center}
\begin{center}
    \vspace*{-1.5cm}
    \hspace*{0.3cm}
    \includegraphics[scale=0.45]{"Answers-3".png}
\end{center}
\begin{center}
    \vspace*{-1.5cm}
    \hspace*{0.7cm}
    \includegraphics[scale=0.94]{"Answers-4".png}
\end{center}
\begin{center}
    \vspace*{-1.0cm}
    \hspace*{0.7cm}
    \includegraphics[scale=0.94]{"Answers-5".png}
\end{center}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
